{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dEgp2_bZgiv",
        "outputId": "b29ee410-1984-4d05-9b7e-a78d29cc43e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmrb9TUR5utU",
        "outputId": "86ca7d31-7e63-441e-da2f-f297e1050ef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVR4Dn84iGJ6"
      },
      "outputs": [],
      "source": [
        "# print(df['symbol'])\n",
        "\n",
        "# actual_tickers = list(set(df['symbol'].to_list()))\n",
        "# len(actual_tickers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUD6Z2FccHED",
        "outputId": "55601c61-b4ca-4b88-9f9b-4d5bf2414b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFq8MIurZScL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "4f3bd031-dfb4-4119-d958-c2cc09b1f6fd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch_geometric'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-81fbf6717329>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNode2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myfinance\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0myf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from torch_geometric.nn import Node2Vec\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from functools import wraps\n",
        "import numpy as np\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8MspTLHsxhKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1d3E8eVZScO"
      },
      "source": [
        "## Data Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ov8jyPGwZScW"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Yv1YJDw0AXAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAVJzUguZScW"
      },
      "source": [
        "### The dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1alk_7lzZScX"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DataRetrieval:\n",
        "    \"\"\"Downloads stocks data an aggregates with technical stock statistics and covariance from other stocks\n",
        "    adds train/test split\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    \"\"\"\n",
        "    Param\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data\n",
        "        end_date : str\n",
        "            end date of the data\n",
        "        ticker_list : list\n",
        "            a list of stock tickers\n",
        "        time_interval : str\n",
        "            download frequency: 1m, 2m, 5m, 15m, 30m, 60m, 90m, 1h, 1d, 5d, 1wk, 1mo, 3mo\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def clean_table(hist_data) -> pd.DataFrame:\n",
        "        hist_data.index = pd.to_datetime(hist_data.index, format='%Y-%m-%d') # Add format string\n",
        "        hist_data.index = hist_data.index.strftime('%Y-%m-%d')\n",
        "        # Reset index\n",
        "        hist_data = hist_data.reset_index()\n",
        "        # Add day 0-n\n",
        "        hist_data[\"day\"] = range(len(hist_data))\n",
        "        # Lowercase all titles\n",
        "        hist_data.columns = hist_data.columns.str.lower()\n",
        "\n",
        "        return hist_data\n",
        "\n",
        "    @staticmethod\n",
        "    def add_covariance(hist_data, lookback) -> pd.DataFrame:\n",
        "        # add covariance matrix as states\n",
        "        hist_data=hist_data.sort_values(['date','tic'],ignore_index=True)\n",
        "        hist_data.index = hist_data.date.factorize()[0]\n",
        "\n",
        "        cov_list = []\n",
        "        return_list = []\n",
        "\n",
        "        # look back is one year\n",
        "        for i in range(lookback,len(hist_data.index.unique())):\n",
        "            data_lookback = hist_data.loc[i-lookback:i,:]\n",
        "            price_lookback = data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
        "            return_lookback = price_lookback.pct_change().dropna()\n",
        "            return_list.append(return_lookback)\n",
        "\n",
        "            covs = return_lookback.cov().values\n",
        "            cov_list.append(covs)\n",
        "\n",
        "        df_cov = pd.DataFrame({'date':hist_data.date.unique()[lookback:],'cov_list':cov_list,'return_list':return_list})\n",
        "        hist_data = hist_data.merge(df_cov, on='date')\n",
        "        hist_data = hist_data.sort_values(['date','tic']).reset_index(drop=True)\n",
        "        return hist_data\n",
        "\n",
        "\n",
        "    def download_data(self, ticker_list, start_date, end_date, time_interval, tech_indicator_list):\n",
        "        self.start = start_date\n",
        "        self.end = end_date\n",
        "        self.time_interval = time_interval\n",
        "\n",
        "        # Download and save the data in a pandas DataFrame\n",
        "        start_date = pd.Timestamp(start_date)\n",
        "        end_date = pd.Timestamp(end_date)\n",
        "        data_df = pd.DataFrame()\n",
        "\n",
        "        # ticker_list.append(\"VIXY\") # append VIXY as reference\n",
        "\n",
        "        for tic in ticker_list:\n",
        "            ticker = yf.Ticker(tic)\n",
        "            ticker_historical = ticker.history(start=start_date, end=end_date, interval=self.time_interval)\n",
        "            # print(tic, len(ticker_historical))\n",
        "\n",
        "            # Clean data\n",
        "            ticker_historical_cleaned = self.clean_table(ticker_historical)\n",
        "            # Add ticker\n",
        "            ticker_historical_cleaned[\"tic\"] = tic\n",
        "\n",
        "            data_df = pd.concat([data_df, ticker_historical_cleaned])\n",
        "\n",
        "        # Sort by day\n",
        "        data_df = data_df.sort_values(by=['day'])\n",
        "\n",
        "        return data_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11yulkSLZScY"
      },
      "outputs": [],
      "source": [
        "#ticker_list = [ticker for ticker in relation_data]\n",
        "\n",
        "TECH_INDICATOR_LIST     = ['middle', 'rsi']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meCjVgG455Fc",
        "outputId": "926f7197-0f6c-4283-b0cf-7cc5306372b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Index(['Date', 'A', 'AAL', 'AAP', 'AAPL', 'ABBV', 'ABC', 'ABT', 'ACGL', 'ACN',\n",
            "       ...\n",
            "       'WYNN', 'XEL', 'XOM', 'XRAY', 'XYL', 'YUM', 'ZBH', 'ZBRA', 'ZION',\n",
            "       'ZTS'],\n",
            "      dtype='object', length=502)\n"
          ]
        }
      ],
      "source": [
        "!pip install openpyxl\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/tickers.xlsx'\n",
        "df = pd.read_excel(file_path, engine='openpyxl')\n",
        "\n",
        "print(df.columns)\n",
        "df = df.drop(df.columns[0], axis=1)\n",
        "#print(ticker_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gi6h9c-XD3qd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "df_embed = pd.read_csv('/content/drive/MyDrive/full_df.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVoTL4256ySt"
      },
      "outputs": [],
      "source": [
        "#ticker_list = df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4fjrzWC6ops",
        "outputId": "e1949b0a-d4e0-4cbc-d229-64a3d76d0cfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       REG\n",
            "1      KEYS\n",
            "2       AEP\n",
            "3       MRO\n",
            "4      ALLE\n",
            "       ... \n",
            "317    SEDG\n",
            "318      CI\n",
            "319      CE\n",
            "320    FOXA\n",
            "321    GOOG\n",
            "Name: symbol, Length: 322, dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "322"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "print(df_embed['symbol'])\n",
        "\n",
        "actual_tickers = list(set(df_embed['symbol'].to_list()))\n",
        "len(actual_tickers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df.to_csv('/content/drive/MyDrive/node2Vec_sampledata.csv', index=False)"
      ],
      "metadata": {
        "id": "k8rjt5oLSINZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/node2Vec_sampledata.csv')"
      ],
      "metadata": {
        "id": "SZQE2hNZnDes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL4QBvMSD7jD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d000e8e8-8f14-470e-9761-bdef583a9d2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              date        open        high         low       close  \\\n",
            "0       2016-01-04   45.110001   45.110001   44.000000   44.919998   \n",
            "1       2016-01-04  135.361578  140.104897  133.783488  138.073349   \n",
            "2       2016-01-04   13.366961   13.472861   13.335583   13.472861   \n",
            "3       2016-01-04    9.488014    9.742231    9.217396    9.455212   \n",
            "4       2016-01-04   60.795555   61.092220   59.866669   60.821110   \n",
            "...            ...         ...         ...         ...         ...   \n",
            "646302  2024-03-28  299.533755  302.329391  299.164335  300.711914   \n",
            "646303  2024-03-28    7.845783    7.984472    7.806158    7.954752   \n",
            "646304  2024-03-28  207.182272  207.272105  202.341107  205.854691   \n",
            "646305  2024-03-28  685.529428  686.535341  677.700793  684.284424   \n",
            "646306  2024-03-28  611.028621  614.314344  608.571781  613.145874   \n",
            "\n",
            "            volume  dividends  stock splits   day   tic  adj close  \n",
            "0         831700.0        0.0           0.0     0  SNPS        NaN  \n",
            "1        1935300.0        0.0           0.0     0   AAP        NaN  \n",
            "2       42076058.0        0.0           0.0     0     T        NaN  \n",
            "3        6279800.0        0.0           0.0     0   NRG        NaN  \n",
            "4        4778100.0        0.0           0.0     0  ISRG        NaN  \n",
            "...            ...        ...           ...   ...   ...        ...  \n",
            "646302   4892300.0        0.0           0.0  2072   CRM        NaN  \n",
            "646303   3128600.0        0.0           0.0  2072   NWL        NaN  \n",
            "646304   5750100.0        0.0           0.0  2072  AMAT        NaN  \n",
            "646305    572400.0        0.0           0.0  2072  CTAS        NaN  \n",
            "646306    309900.0        0.0           0.0  2072   MLM        NaN  \n",
            "\n",
            "[646307 rows x 11 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df)\n",
        "df['close_pct_change'] = (df['close'] - df['close'].shift(1)) / df['close'].shift(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N78ZjRWEcArW"
      },
      "outputs": [],
      "source": [
        "output_file_path = '/content/drive/MyDrive/test_data_320_SP500.xlsx'\n",
        "df.to_excel(output_file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BSyEYHVjVX1"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/test_data_320_SP500.xlsx'\n",
        "df = pd.read_excel(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n3-Yo3npDct"
      },
      "outputs": [],
      "source": [
        "quantile1 = pd.read_csv('/content/drive/MyDrive/saved_q01_.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(quantile1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4THUwPFxkLJ",
        "outputId": "1978f989-1045-4a7c-857f-45903d1a3f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             A       AAL      AAPL      ABBV       ABT      ACGL       ACN  \\\n",
            "A     1.000000  0.430264  0.455135  0.451925  0.596241  0.353478  0.596027   \n",
            "AAL   0.430264  1.000000  0.307744  0.280196  0.406048  0.264996  0.368987   \n",
            "AAPL  0.455135  0.307744  1.000000  0.269007  0.418096  0.249338  0.456026   \n",
            "ABBV  0.451925  0.280196  0.269007  1.000000  0.479327  0.142457  0.266560   \n",
            "ABT   0.596241  0.406048  0.418096  0.479327  1.000000  0.400294  0.541320   \n",
            "...        ...       ...       ...       ...       ...       ...       ...   \n",
            "XOM   0.465948  0.252601  0.324733  0.285589  0.484625  0.291843  0.409552   \n",
            "XYL   0.564414  0.387567  0.374624  0.327075  0.462696  0.374706  0.502788   \n",
            "YUM   0.439659  0.350732  0.344477  0.237796  0.469300  0.331982  0.465366   \n",
            "ZBRA  0.449857  0.349323  0.353535  0.241263  0.380962  0.183166  0.373879   \n",
            "ZTS   0.478929  0.321288  0.342448  0.374725  0.522309  0.278289  0.457981   \n",
            "\n",
            "          ADBE       ADI       ADM  ...       WMT       WRB       WST  \\\n",
            "A     0.529330  0.518502  0.409023  ...  0.247186  0.421694  0.462219   \n",
            "AAL   0.373671  0.384298  0.376164  ...  0.188259  0.320661  0.318161   \n",
            "AAPL  0.447677  0.470573  0.289590  ...  0.176164  0.289007  0.329740   \n",
            "ABBV  0.264083  0.270931  0.327435  ...  0.195978  0.257647  0.279485   \n",
            "ABT   0.526515  0.428463  0.380998  ...  0.328839  0.495266  0.461678   \n",
            "...        ...       ...       ...  ...       ...       ...       ...   \n",
            "XOM   0.315565  0.355327  0.395583  ...  0.239946  0.404724  0.246690   \n",
            "XYL   0.462726  0.444858  0.442156  ...  0.240306  0.440884  0.334421   \n",
            "YUM   0.443112  0.364944  0.368551  ...  0.284355  0.373154  0.348414   \n",
            "ZBRA  0.372866  0.368938  0.303484  ...  0.112301  0.258491  0.289203   \n",
            "ZTS   0.387460  0.298731  0.293096  ...  0.224130  0.367401  0.360917   \n",
            "\n",
            "            WY      WYNN       XOM       XYL       YUM      ZBRA       ZTS  \n",
            "A     0.473209  0.314072  0.465948  0.564414  0.439659  0.449857  0.478929  \n",
            "AAL   0.366918  0.289874  0.252601  0.387567  0.350732  0.349323  0.321288  \n",
            "AAPL  0.355353  0.221309  0.324733  0.374624  0.344477  0.353535  0.342448  \n",
            "ABBV  0.280225  0.226599  0.285589  0.327075  0.237796  0.241263  0.374725  \n",
            "ABT   0.426332  0.276948  0.484625  0.462696  0.469300  0.380962  0.522309  \n",
            "...        ...       ...       ...       ...       ...       ...       ...  \n",
            "XOM   0.379024  0.309674  1.000000  0.553637  0.351849  0.321199  0.292207  \n",
            "XYL   0.419403  0.332035  0.553637  1.000000  0.355603  0.384178  0.425224  \n",
            "YUM   0.316080  0.266829  0.351849  0.355603  1.000000  0.285682  0.375435  \n",
            "ZBRA  0.281472  0.251180  0.321199  0.384178  0.285682  1.000000  0.294086  \n",
            "ZTS   0.253830  0.196376  0.292207  0.425224  0.375435  0.294086  1.000000  \n",
            "\n",
            "[371 rows x 371 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L38niJHC-wRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f3268b9-066f-4d32-d9da-3342dc0e2264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[193, 5], edge_index=[2, 37056], edge_attr=[37056, 3])\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Load quantile correlation matrices\n",
        "quantile1 = pd.read_csv('/content/drive/MyDrive/saved_q01_.csv', index_col=0)\n",
        "quantile2 = pd.read_csv('/content/drive/MyDrive/saved_q02_.csv', index_col=0)\n",
        "quantile3 = pd.read_csv('/content/drive/MyDrive/saved_q03_.csv', index_col=0)\n",
        "\n",
        "final_stocks = pd.read_csv('/content/drive/MyDrive/final_columns.csv')\n",
        "list_stocks = final_stocks['stocks'].to_list()\n",
        "\n",
        "common_stocks = list(set(list_stocks).intersection(quantile1.index))\n",
        "\n",
        "# Filter quantile DataFrames based on common stocks\n",
        "quantile1 = quantile1.loc[common_stocks, common_stocks]\n",
        "quantile2 = quantile2.loc[common_stocks, common_stocks]\n",
        "quantile3 = quantile3.loc[common_stocks, common_stocks]\n",
        "\n",
        "# Ensure the matrices have the same shape and stocks\n",
        "assert quantile1.shape == quantile2.shape == quantile3.shape\n",
        "stocks = quantile1.index.tolist()\n",
        "\n",
        "# Ensure the matrices have the same shape and stocks\n",
        "assert quantile1.shape == quantile2.shape == quantile3.shape\n",
        "stocks = quantile1.index.tolist()\n",
        "\n",
        "edge_index_list = []\n",
        "edge_features_list = []\n",
        "\n",
        "# Enumerate stocks to get their indices\n",
        "enumerated_stocks = {stock: idx for idx, stock in enumerate(stocks)}\n",
        "\n",
        "# Iterate over the upper triangle of the correlation matrices to avoid duplicate edges\n",
        "for i, stock1 in enumerate(stocks):\n",
        "    for j, stock2 in enumerate(stocks):\n",
        "        if i != j:\n",
        "            edge_index_list.append([enumerated_stocks[stock1], enumerated_stocks[stock2]])\n",
        "            edge_features_list.append([\n",
        "                quantile1.iloc[i, j],\n",
        "                quantile2.iloc[i, j],\n",
        "                quantile3.iloc[i, j]\n",
        "            ])\n",
        "\n",
        "edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "edge_features = torch.tensor(edge_features_list, dtype=torch.float)\n",
        "\n",
        "# Create dummy node features (replace with actual features if available)\n",
        "num_stocks = len(stocks)\n",
        "node_features = torch.randn(num_stocks, 5)  # Example: 5 random features per stock\n",
        "\n",
        "# Create the Data object\n",
        "data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
        "\n",
        "# Print the Data object to verify\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SZ-2ani5rZy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PBYRyVQ9cyo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = '/content/drive/MyDrive/tickers.xlsx'\n",
        "\n",
        "\n",
        "df_embed = pd.read_csv('/content/drive/MyDrive/full_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VC8vL-765pZF"
      },
      "outputs": [],
      "source": [
        "df= pd.read_csv('/content/drive/MyDrive/allfields_merged_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_data = df[df['tic'].isin(common_stocks)]"
      ],
      "metadata": {
        "id": "zUwlXdzGnVSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mYdWwN3n6mn",
        "outputId": "c588d20d-df87-4b7a-d044-4012702948c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              date        open        high         low       close    volume  \\\n",
            "1446    2016-06-20  101.598981  102.225120  101.557785  101.681366   5951000   \n",
            "1447    2018-04-30  142.245131  145.060836  141.433238  144.620346  12954700   \n",
            "1448    2018-07-03  136.777444  137.177282  135.864780  136.012543   1437700   \n",
            "1449    2018-07-11  138.107338  138.820089  137.072987  137.872650   3203800   \n",
            "1450    2018-07-18  138.941796  138.959171  137.168619  137.272919   3824000   \n",
            "...            ...         ...         ...         ...         ...       ...   \n",
            "382792  2024-03-27  128.138651  128.138651  125.175287  126.136642   2416400   \n",
            "382793  2024-03-27  128.138651  128.138651  125.175287  126.136642   2416400   \n",
            "382794  2024-03-27  128.138651  128.138651  125.175287  126.136642   2416400   \n",
            "382795  2024-03-28  127.742225  128.812609  127.246678  128.198135   3204100   \n",
            "382796  2024-03-28  127.742225  128.812609  127.246678  128.198135   3204100   \n",
            "\n",
            "        dividends  stock splits   day  tic  adj close  close_pct_change  \\\n",
            "1446          0.0           0.0   116  MCD        NaN          2.472836   \n",
            "1447          0.0           0.0   584  MCD        NaN          3.843469   \n",
            "1448          0.0           0.0   629  MCD        NaN          0.966352   \n",
            "1449          0.0           0.0   634  MCD        NaN          0.085620   \n",
            "1450          0.0           0.0   639  MCD        NaN          1.276931   \n",
            "...           ...           ...   ...  ...        ...               ...   \n",
            "382792        0.0           0.0  2071  KMB        NaN         -0.218451   \n",
            "382793        0.0           0.0  2071  KMB        NaN         -0.218451   \n",
            "382794        0.0           0.0  2071  KMB        NaN         -0.218451   \n",
            "382795        0.0           0.0  2072  KMB        NaN          1.903826   \n",
            "382796        0.0           0.0  2072  KMB        NaN          1.903826   \n",
            "\n",
            "         upperband  middleband   lowerband  moving_averages_list  cashflow  \\\n",
            "1446    101.748281  100.692595   99.636909            100.134482       NaN   \n",
            "1447    143.361912  139.023467  134.685022            116.460381       NaN   \n",
            "1448    149.125418  141.569788  134.014158            118.201044       NaN   \n",
            "1449    146.321517  139.915261  133.509006            118.359799       NaN   \n",
            "1450    141.868631  138.296379  134.724127            118.513587       NaN   \n",
            "...            ...         ...         ...                   ...       ...   \n",
            "382792  127.405858  123.597895  119.789932            110.453196       NaN   \n",
            "382793  127.405858  123.597895  119.789932            110.453196       NaN   \n",
            "382794  127.405858  123.597895  119.789932            110.453196       NaN   \n",
            "382795  127.734775  124.061947  120.389119            110.461756       NaN   \n",
            "382796  127.734775  124.061947  120.389119            110.461756       NaN   \n",
            "\n",
            "                                               Embeddings  \n",
            "1446    [-0.18811035, -0.33901063, -0.15162353, 0.3310...  \n",
            "1447    [-0.7437515, -0.5314064, 0.40813893, 0.2690349...  \n",
            "1448    [-1.0029418, -0.6294759, 0.40359396, -0.171846...  \n",
            "1449    [0.08523352, -0.30669612, 0.53371084, 0.039528...  \n",
            "1450    [-0.5601087, -0.3775015, 0.6287929, 0.31740242...  \n",
            "...                                                   ...  \n",
            "382792  [0.6096594, -0.2192688, 0.43219757, 0.5309448,...  \n",
            "382793  [0.28718948, -0.20968212, 0.11906138, 0.193725...  \n",
            "382794  [0.4766605, 0.26540816, 0.61904347, -0.0181772...  \n",
            "382795  [0.22477321, -0.32201627, 0.8773001, 0.4985672...  \n",
            "382796  [0.25261334, -0.29051512, 0.3742635, 0.4493164...  \n",
            "\n",
            "[371665 rows x 18 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_data.to_csv('/content/drive/MyDrive/filtered_data_final.csv', index=False)"
      ],
      "metadata": {
        "id": "jme7L4yPoB2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJWyCUa4WV-a",
        "outputId": "2a37000f-6bb4-47d8-ccbf-02e0059511c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              date        open        high         low       close   volume  \\\n",
            "0       2016-01-04  136.030029  138.060457  135.447208  137.759659  1461700   \n",
            "1       2016-01-13  130.878716  131.724741  126.817845  127.146843  1671200   \n",
            "2       2016-01-19  128.105634  132.946720  128.086829  131.527298  1843800   \n",
            "3       2016-02-04  122.766367  126.874242  122.766367  126.686241  2151600   \n",
            "4       2016-02-05  125.642832  127.005855  123.800390  125.069420  1567200   \n",
            "...            ...         ...         ...         ...         ...      ...   \n",
            "382792  2024-03-27  128.138651  128.138651  125.175287  126.136642  2416400   \n",
            "382793  2024-03-27  128.138651  128.138651  125.175287  126.136642  2416400   \n",
            "382794  2024-03-27  128.138651  128.138651  125.175287  126.136642  2416400   \n",
            "382795  2024-03-28  127.742225  128.812609  127.246678  128.198135  3204100   \n",
            "382796  2024-03-28  127.742225  128.812609  127.246678  128.198135  3204100   \n",
            "\n",
            "        dividends  stock splits   day  tic  adj close  close_pct_change  \\\n",
            "0             0.0           0.0     0   CI        NaN          5.002599   \n",
            "1             0.0           0.0     7   CI        NaN          1.294685   \n",
            "2             0.0           0.0    10   CI        NaN          1.506932   \n",
            "3             0.0           0.0    22   CI        NaN         14.534393   \n",
            "4             0.0           0.0    23   CI        NaN          1.548146   \n",
            "...           ...           ...   ...  ...        ...               ...   \n",
            "382792        0.0           0.0  2071  KMB        NaN         -0.218451   \n",
            "382793        0.0           0.0  2071  KMB        NaN         -0.218451   \n",
            "382794        0.0           0.0  2071  KMB        NaN         -0.218451   \n",
            "382795        0.0           0.0  2072  KMB        NaN          1.903826   \n",
            "382796        0.0           0.0  2072  KMB        NaN          1.903826   \n",
            "\n",
            "         upperband  middleband   lowerband  moving_averages_list  cashflow  \\\n",
            "0              NaN         NaN         NaN            137.759659       NaN   \n",
            "1              NaN         NaN         NaN            131.943287       NaN   \n",
            "2              NaN         NaN         NaN            131.411960       NaN   \n",
            "3       133.856431  127.835405  121.814379            128.887513       NaN   \n",
            "4       133.106582  127.444360  121.782138            128.728425       NaN   \n",
            "...            ...         ...         ...                   ...       ...   \n",
            "382792  127.405858  123.597895  119.789932            110.453196       NaN   \n",
            "382793  127.405858  123.597895  119.789932            110.453196       NaN   \n",
            "382794  127.405858  123.597895  119.789932            110.453196       NaN   \n",
            "382795  127.734775  124.061947  120.389119            110.461756       NaN   \n",
            "382796  127.734775  124.061947  120.389119            110.461756       NaN   \n",
            "\n",
            "                                               Embeddings  \n",
            "0       [0.11369663, 0.022350736, 0.47559357, 0.717692...  \n",
            "1       [0.20965375, 0.50863487, 1.1025391, -0.1415373...  \n",
            "2       [0.038604736, 0.04860618, 0.7443764, 0.4370339...  \n",
            "3       [0.401371, -0.04229927, 0.7668495, 0.5751209, ...  \n",
            "4       [0.18973118, 0.06568146, 0.6185845, 0.29078504...  \n",
            "...                                                   ...  \n",
            "382792  [0.6096594, -0.2192688, 0.43219757, 0.5309448,...  \n",
            "382793  [0.28718948, -0.20968212, 0.11906138, 0.193725...  \n",
            "382794  [0.4766605, 0.26540816, 0.61904347, -0.0181772...  \n",
            "382795  [0.22477321, -0.32201627, 0.8773001, 0.4985672...  \n",
            "382796  [0.25261334, -0.29051512, 0.3742635, 0.4493164...  \n",
            "\n",
            "[382797 rows x 18 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ccsEQFv4WCWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_H0PdGF587k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56deccf8-dc9a-4322-af32-ce9d4d71926d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       REG\n",
            "1      KEYS\n",
            "2       AEP\n",
            "3       MRO\n",
            "4      ALLE\n",
            "       ... \n",
            "317    SEDG\n",
            "318      CI\n",
            "319      CE\n",
            "320    FOXA\n",
            "321    GOOG\n",
            "Name: symbol, Length: 322, dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "322"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "print(df_embed['symbol'])\n",
        "\n",
        "actual_tickers = list(set(df_embed['symbol'].to_list()))\n",
        "len(actual_tickers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBef1y246dsT"
      },
      "outputs": [],
      "source": [
        "# print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHtGy1n-ZScZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09dde31d-9b46-4ca8-b321-9df7e8475d6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "314"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "actual_tickers = list(set(df.tic.to_list()))\n",
        "len(actual_tickers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def enumerate_companies(companies_dict):\n",
        "    enumerated_companies = {}\n",
        "    index = 0\n",
        "\n",
        "    for company in companies_dict.keys():\n",
        "        enumerated_companies[company] = index\n",
        "        index += 1\n",
        "\n",
        "    return enumerated_companies\n",
        "\n",
        "enumerated_companies = enumerate_companies(relation_data)\n",
        "enumerated_companies[\"AAPL\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU35LV3vIxEc",
        "outputId": "3bd1c50f-735c-4794-90e3-dbcdb96b305d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXv2OgtGZScZ"
      },
      "outputs": [],
      "source": [
        "# Max Drawdown\n",
        "def calc_mdd(stock_prices):\n",
        "    \"\"\"Calculates the Maximal drawdown (MDD) of a given list.\n",
        "    Returns MDD as absolute value and as percentage value\n",
        "    \"\"\"\n",
        "\n",
        "    max_drawdown_abs = 0.0\n",
        "    max_drawdown_pct = 0.0\n",
        "    peak = stock_prices[0]  # Initialize peak as the first price\n",
        "    for price in stock_prices:\n",
        "        if price > peak:\n",
        "            peak = price\n",
        "        drawdown_abs = peak - price\n",
        "        drawdown_pct = (peak - price) / peak\n",
        "        if drawdown_abs > max_drawdown_abs:\n",
        "            max_drawdown_abs = drawdown_abs\n",
        "            max_drawdown_pct = drawdown_pct\n",
        "    return max_drawdown_abs, max_drawdown_pct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UgYD6UiZScZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba6991a-79e7-4a21-e5ba-7807d57fc5ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         date        open        high         low       close    volume  \\\n",
            "0  2016-01-04   45.110001   45.110001   44.000000   44.919998    831700   \n",
            "1  2016-01-04  135.361578  140.104897  133.783488  138.073349   1935300   \n",
            "2  2016-01-04   13.366961   13.472861   13.335583   13.472861  42076058   \n",
            "3  2016-01-04    9.488014    9.742231    9.217396    9.455212   6279800   \n",
            "4  2016-01-04   60.795555   61.092220   59.866669   60.821110   4778100   \n",
            "\n",
            "   dividends  stock splits  day   tic  adj close  close_pct_change  \n",
            "0        0.0           0.0    0  SNPS        NaN               NaN  \n",
            "1        0.0           0.0    0   AAP        NaN          2.073761  \n",
            "2        0.0           0.0    0     T        NaN         -0.902422  \n",
            "3        0.0           0.0    0   NRG        NaN         -0.298203  \n",
            "4        0.0           0.0    0  ISRG        NaN          5.432549  \n"
          ]
        }
      ],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzDnedPYZSca"
      },
      "source": [
        "## Create Graph Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlhCPG9TZSca",
        "outputId": "ed08313d-0a63-4050-825a-e40afbf5ef6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[29.4, 495275.4]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np\n",
        "# Sample edge list and edge features (replace with your actual data)\n",
        "\n",
        "\n",
        "\n",
        "# data for node features\n",
        "\n",
        "node_features_list = []\n",
        "\n",
        "\n",
        "for company in common_stocks:\n",
        "    df_company = df[df['tic'] == company]\n",
        "\n",
        "\n",
        "    company_stock_std = round(np.std(df_company.close, ddof=0),1)\n",
        "    if company_stock_std == \"nan\":\n",
        "        print(company, company_stock_std)\n",
        "\n",
        "    company_volume_std = round(np.std(df_company.volume, ddof=0),1)\n",
        "\n",
        "    #company_mdd = round(calc_mdd(df_company.high)[1], 1)\n",
        "\n",
        "    comapny_dividens_sum = round(np.sum(df_company.dividends), 5)\n",
        "    comapny_stocksplits_sum = round(np.sum(df_company[\"stock splits\"]), 5)\n",
        "\n",
        "    #percentage_increase = round(df_company.close.to_list()[-1] / df_company.close.to_list()[0], 3)\n",
        "\n",
        "    company_upperband = round(np.std(df_company.upperband, ddof=0),2)\n",
        "    company_lowerband = round(np.std(df_company.lowerband, ddof=0),2)\n",
        "    company_middleband = round(np.std(df_company.middleband, ddof=0),2)\n",
        "    company_moving_averages_list = round(np.std(df_company.moving_averages_list, ddof=0),2)\n",
        "    company_cashflow = round(np.std(df_company.cashflow, ddof=0), 2)\n",
        "\n",
        "    node_features_list.append([company_stock_std, company_volume_std])\n",
        "\n",
        "print(node_features_list[0])\n",
        "\n",
        "node_features = torch.tensor(node_features_list, dtype=torch.float)\n",
        "# Number of nodes in the graph (assuming nodes are indexed from 0 to max_node_idx)\n",
        "num_nodes = edge_index.max().item() + 1\n",
        "\n",
        "\n",
        "data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features) # edge_features=edge_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Z3j0PqxZSca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0568ea1-08ad-454f-c99c-11e2564447a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "193\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(2)\n",
        "# get the nodes\n",
        "nodes = data.edge_index.t().numpy()\n",
        "nodes = np.unique(list(nodes[:,0]) + list(nodes[:,1]))\n",
        "\n",
        "# np.random.shuffle(nodes) # shuffle node order\n",
        "print(len(nodes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb9E-so0ZScb"
      },
      "source": [
        "## Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6O4lYqiZScb"
      },
      "outputs": [],
      "source": [
        "# get train test and val sizes: (70% - 15% - 15%)\n",
        "train_size = int(len(nodes)*0.7)\n",
        "test_size = int(len(nodes)*0.85) - train_size\n",
        "val_size = len(nodes) - train_size - test_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGeeeUBxZScb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c89ca8f6-1dfe-497e-d39e-9b2e4f71da17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135 29 29\n",
            "True\n",
            "train set\t [0 1 2 3 4 5 6 7 8 9]\n",
            "test set \t [135 136 137 138 139 140 141 142 143 144]\n",
            "val set  \t [164 165 166 167 168 169 170 171 172 173]\n"
          ]
        }
      ],
      "source": [
        "# get train test and validation set of nodes\n",
        "train_set = nodes[0:train_size]\n",
        "test_set = nodes[train_size:train_size+test_size]\n",
        "val_set = nodes[train_size+test_size:]\n",
        "\n",
        "\n",
        "print(len(train_set),len(test_set),len(val_set))\n",
        "print(len(train_set)+len(test_set)+len(val_set) == len(nodes))\n",
        "\n",
        "print(\"train set\\t\",train_set[:10])\n",
        "print(\"test set \\t\",test_set[:10])\n",
        "print(\"val set  \\t\",val_set[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLugLwSSrsZ9"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZohMUB0cZScc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373a3e10-a1a3-45e2-da6a-e9b817fde543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train mask \t tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "test mask  \t tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "val mask   \t tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "# build test train val masks\n",
        "\n",
        "train_mask = torch.zeros(len(nodes),dtype=torch.long, device=device)\n",
        "for i in train_set:\n",
        "    if i != 83:\n",
        "        train_mask[i] = 1.\n",
        "\n",
        "test_mask = torch.zeros(len(nodes),dtype=torch.long, device=device)\n",
        "for i in test_set:\n",
        "    test_mask[i] = 1.\n",
        "\n",
        "val_mask = torch.zeros(len(nodes),dtype=torch.long, device=device)\n",
        "for i in val_set:\n",
        "    val_mask[i] = 1.\n",
        "\n",
        "print(\"train mask \\t\",train_mask[0:15])\n",
        "print(\"test mask  \\t\",test_mask[0:15])\n",
        "print(\"val mask   \\t\",val_mask[0:15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFsEYgIUZScc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ce0deb-aa58-4adb-b21b-a276f5ecd1e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after\t\t Data(x=[193, 2], edge_index=[2, 37056], edge_attr=[37056, 3], train_mask=[193], test_mask=[193], val_mask=[193])\n"
          ]
        }
      ],
      "source": [
        "# add masks\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "data.val_mask = val_mask\n",
        "\n",
        "print(\"after\\t\\t\",data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OulKzGZAR19s",
        "outputId": "bcbdf6fc-1189-4bf8-8c90-77ee16ee1800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch_geometric.data.data.Data'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_features_df = pd.DataFrame(data.x.numpy())\n",
        "node_features_df.to_csv('/content/drive/MyDrive/node_features.csv', index=False)\n",
        "\n",
        "# Convert edge index to a DataFrame and save to CSV\n",
        "edge_index_df = pd.DataFrame(data.edge_index.numpy().T, columns=['source', 'target'])\n",
        "edge_index_df.to_csv('/content/drive/MyDrive/edge_index.csv', index=False)\n",
        "\n",
        "# If edge attributes are present, convert them to a DataFrame and save to CSV\n",
        "if data.edge_attr is not None:\n",
        "    edge_attr_df = pd.DataFrame(data.edge_attr.numpy())\n",
        "    edge_attr_df.to_csv('/content/drive/MyDrive/edge_attributes.csv', index=False)\n",
        "\n",
        "print(\"Data has been saved to CSV files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzMU-_-xVk2l",
        "outputId": "08dc7db5-2e43-4d56-8de4-c01495b1ca46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been saved to CSV files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.data import Data"
      ],
      "metadata": {
        "id": "nAlnhEtFBkic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_features_df = pd.read_csv('/content/drive/MyDrive/node_features.csv')\n",
        "x = torch.tensor(node_features_df.values, dtype=torch.float)\n",
        "\n",
        "# Load edge index from CSV\n",
        "edge_index_df = pd.read_csv('/content/drive/MyDrive/edge_index.csv')\n",
        "edge_index = torch.tensor(edge_index_df.values.T, dtype=torch.long)\n",
        "\n",
        "# Load edge attributes from CSV (if exists)\n",
        "try:\n",
        "    edge_attr_df = pd.read_csv('/content/drive/MyDrive/edge_attributes.csv')\n",
        "    edge_attr = torch.tensor(edge_attr_df.values, dtype=torch.float)\n",
        "except FileNotFoundError:\n",
        "    edge_attr = None\n",
        "\n",
        "# Create the Data object\n",
        "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)"
      ],
      "metadata": {
        "id": "8SfaLQRJYLvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcP4Wxg3ZScc"
      },
      "outputs": [],
      "source": [
        "torch.set_num_threads(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLl_bFGLZJu9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.nn.models import Node2Vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MRF4mmSlZOOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "JrRPcvmWL6nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.3.1+cpu121.html\n",
        "#!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.3.1+cpu121.html\n",
        "!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-2.3.1+cpu121.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0H_nIKCMGwA",
        "outputId": "811b7d36-072c-479a-8d37-fc4f8dafab25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyg-lib -q"
      ],
      "metadata": {
        "id": "3Be1shplM6zN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c872067f-1dab-49fe-d574-fdf72d7ff8bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pyg-lib (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pyg-lib\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !condacolab KERNEL RESTART\n",
        "# print(\"Restarting of kernel...\")\n",
        "# get_ipython().kernel.do_shutdown(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twMcHw_4NZiw",
        "outputId": "e71b6ed5-47e2-438f-e843-6d521026779a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: condacolab: command not found\n",
            "Restarting of kernel...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSHv30QzZScd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3521eb39-541c-433b-a517-7a0d8e1dc02d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model = Node2Vec(data.edge_index, embedding_dim=128, walk_length=20,\n",
        "             context_size=10, walks_per_node=10,\n",
        "             num_negative_samples=1, p=1, q=1, sparse=True).to(device)\n",
        "\n",
        "loader = model.loader(batch_size=128, shuffle=True, num_workers=4)\n",
        "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
        "\n",
        "torch.set_num_threads(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNbDrC1EZScd"
      },
      "outputs": [],
      "source": [
        "torch.set_num_threads(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyQEImWQZScd"
      },
      "source": [
        "## Train Node2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uLMOnrYZScd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d250b008-cc39-4f01-c616-f5fd49107cd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Loss: 7.1858\n",
            "Epoch: 20, Loss: 5.2104\n",
            "Epoch: 30, Loss: 3.9636\n",
            "Epoch: 40, Loss: 3.2485\n",
            "Epoch: 50, Loss: 2.7811\n",
            "Epoch: 60, Loss: 2.4585\n",
            "Epoch: 70, Loss: 2.2584\n",
            "Epoch: 80, Loss: 2.1085\n",
            "Epoch: 90, Loss: 2.0003\n",
            "Epoch: 100, Loss: 1.9140\n",
            "Epoch: 110, Loss: 1.8787\n",
            "Epoch: 120, Loss: 1.7988\n",
            "Epoch: 130, Loss: 1.7813\n",
            "Epoch: 140, Loss: 1.7608\n",
            "Epoch: 150, Loss: 1.7518\n",
            "Epoch: 160, Loss: 1.7326\n",
            "Epoch: 170, Loss: 1.7128\n",
            "Epoch: 180, Loss: 1.7072\n",
            "Epoch: 190, Loss: 1.6804\n",
            "Epoch: 200, Loss: 1.6810\n"
          ]
        }
      ],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for pos_rw, neg_rw in loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    z = model()\n",
        "    acc = model.test(z[data.train_mask], data.y[data.train_mask],\n",
        "                     z[data.test_mask], data.y[data.test_mask],\n",
        "                     max_iter=10)\n",
        "    return acc\n",
        "\n",
        "\n",
        "for epoch in range(1, 201):\n",
        "    loss = train()\n",
        "    #acc = test()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fS0HKKxZSce"
      },
      "source": [
        "## Detach embeddings and  store all to csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyQBFuntZSce"
      },
      "outputs": [],
      "source": [
        "z = model()\n",
        "\n",
        "# from tensor to numpy\n",
        "emb = z.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2iTHHeOZSce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1fadd1e4-12a4-4845-8334-ad985a3793e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/node2vec_embeedings.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "csv_file_path = \"/content/drive/MyDrive/node2vec_embeedings.csv\"\n",
        "csv_file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNwty8OyZScf"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "# Write the data to the CSV file\n",
        "with open(csv_file_path, 'w', newline='') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "    for row in emb:\n",
        "        csv_writer.writerow(row)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/node2vec_embeedings.csv')\n"
      ],
      "metadata": {
        "id": "Y6xT9zW2JLZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q2uZzfSJdvT",
        "outputId": "d2cd452d-0ae4-430b-f2f5-ea9aab0fd680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     -0.8028928  0.6364976  0.089480005  0.52772045  -0.35956797  -0.77462703  \\\n",
            "0     -0.091657  -0.022072    -0.428367   -0.132408     0.199133    -0.044436   \n",
            "1      0.054191  -0.165534    -0.077147   -0.096555    -0.160630     0.108926   \n",
            "2      0.051981  -0.028293     0.086656    0.013554     0.039774    -0.010397   \n",
            "3      0.916243  -0.313245     0.508415    0.728061    -0.430762    -0.852728   \n",
            "4      0.027382  -0.036152     0.289892   -0.244340    -0.084346    -0.059694   \n",
            "..          ...        ...          ...         ...          ...          ...   \n",
            "187    0.347121   0.614322     0.104573    1.390100     0.268391     0.214828   \n",
            "188    0.012300   0.051958    -0.025094   -0.209117     0.002489    -0.111686   \n",
            "189   -0.442247   0.293643     0.455382    0.115346    -0.311267     0.199858   \n",
            "190   -0.273133   0.562157    -0.098264   -0.670370    -0.011363    -0.483353   \n",
            "191    0.171485   0.217481    -0.001379    0.171704    -0.005342     0.078376   \n",
            "\n",
            "     0.16475296  0.8548588  0.34001794  0.1377586  ...  -0.43368176  \\\n",
            "0     -0.943952  -0.069859   -0.878352   0.831263  ...     0.024114   \n",
            "1      0.007270  -0.003429    0.261749   0.004180  ...     0.088476   \n",
            "2      0.146986   0.109556    0.009777   0.135220  ...    -0.037685   \n",
            "3      0.620414  -0.641693   -0.534032  -0.821298  ...    -0.366699   \n",
            "4     -0.345429  -0.063872    0.035295  -0.129593  ...    -0.042825   \n",
            "..          ...        ...         ...        ...  ...          ...   \n",
            "187   -0.673398  -0.189528   -0.484672   0.565897  ...     0.171626   \n",
            "188   -0.078500   0.263525   -0.078200  -0.036778  ...    -0.197068   \n",
            "189    0.206903  -0.607882   -0.308561   0.278981  ...    -0.649431   \n",
            "190    0.920448  -0.233702   -0.328630   0.965088  ...    -0.131098   \n",
            "191   -0.221203   0.066098    0.015514   0.141598  ...    -0.041512   \n",
            "\n",
            "     -0.342802  -0.8196206  0.03703131  0.23735745  0.1544178  -0.22741  \\\n",
            "0     0.770953   -0.416401   -0.635084    0.066832   0.369760 -0.726429   \n",
            "1    -0.032777   -0.024128    0.025478   -0.101595  -0.029599  0.412733   \n",
            "2     0.059177    0.036114    0.039944    0.076732  -0.149593  0.067162   \n",
            "3     0.137505   -0.202961   -0.377166   -0.435285   0.181114  0.198871   \n",
            "4    -0.036806   -0.433159    0.087275    0.186775  -0.141068 -0.115679   \n",
            "..         ...         ...         ...         ...        ...       ...   \n",
            "187  -0.855852   -0.551348   -0.523221   -0.541614  -0.390859  0.121051   \n",
            "188  -0.084300    0.110627   -0.404242   -0.073579  -0.024475  0.197252   \n",
            "189  -0.397653    0.581248    0.321649    0.313399  -0.385878  0.140859   \n",
            "190   1.149588    0.451416   -0.205513   -0.636556   0.000182  0.260136   \n",
            "191  -0.132728    0.041983    0.639537   -0.163409  -0.154396 -0.754078   \n",
            "\n",
            "     -0.42500433  0.13656676  -0.2184929  \n",
            "0      -0.127799    0.025798    0.413085  \n",
            "1      -0.105170    0.047145   -0.004221  \n",
            "2       0.013916    0.091576    0.066026  \n",
            "3       0.170954   -0.188288    0.090362  \n",
            "4       0.100567   -0.039355    0.022443  \n",
            "..           ...         ...         ...  \n",
            "187     0.737089   -0.721850   -0.682174  \n",
            "188     0.163834   -0.113574   -0.060205  \n",
            "189     0.257709    0.574515    0.509641  \n",
            "190    -0.758582   -0.131833   -0.548140  \n",
            "191     0.226583   -0.202968    0.326325  \n",
            "\n",
            "[192 rows x 128 columns]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}